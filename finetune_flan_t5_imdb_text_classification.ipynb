{"cells":[{"cell_type":"markdown","metadata":{"id":"BYiw7RHYP9fl"},"source":["# Fine-tune FLAN-T5 for IMDB text classification\n"]},{"cell_type":"markdown","metadata":{"id":"nPKzuFL8P9fs"},"source":["## 1. Setup Development Environment\n","\n","Our first step is to install the Hugging Face Libraries, including transformers and datasets. Running the following cell will install all the required packages."]},{"cell_type":"markdown","metadata":{"id":"wz7N03G8CtL6"},"source":["\n","## INTRO\n","In this blog, you will learn how to fine-tune [google/flan-t5-base](https://huggingface.co/google/flan-t5-base) for imdb text classification using Hugging Face Transformers.\n","\n","If you already know T5, FLAN-T5 is just better at everything. For the same number of parameters, these models have been fine-tuned on more than 1000 additional tasks covering also more languages.\n","\n","In this example we will use the [imdb](https://huggingface.co/datasets/imdb) Large Movie Review Dataset.\n","\n","This is a dataset for binary sentiment classification containing substantially more data than previous benchmark datasets. We provide a set of 25,000 highly polar movie reviews for training, and 25,000 for testing. There is additional unlabeled data for use as well.\n","\n","You will learn how to:\n","\n","1. [Setup Development Environment](#1-setup-development-environment)\n","2. [Load and prepare imdb dataset](#2-load-and-prepare-imdb-dataset)\n","3. [Fine-tune and evaluate FLAN-T5](#3-fine-tune-and-evaluate-flan-t5)\n","4. [Run Inference and run inference and classification report](#4-run-inference-run-inference-and-classification-report)\n","\n","Before we can start, make sure you have a [Hugging Face Account](https://huggingface.co/join) to save artifacts and experiments.\n","\n","## Quick intro: FLAN-T5, just a better T5\n","\n","FLAN-T5 released with the [Scaling Instruction-Finetuned Language Models](https://arxiv.org/pdf/2210.11416.pdf) paper is an enhanced version of T5 that has been finetuned in a mixture of tasks. The paper explores instruction finetuning with a particular focus on (1) scaling the number of tasks, (2) scaling the model size, and (3) finetuning on chain-of-thought data. The paper discovers that overall instruction finetuning is a general method for improving the performance and usability of pretrained language models.\n","\n","\n","* Paper: https://arxiv.org/abs/2210.11416\n","* Official repo: https://github.com/google-research/t5x\n","---\n"]},{"cell_type":"markdown","metadata":{"id":"fgrTe18OCtL7"},"source":["## 1. Setup Development Environment\n"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":52794,"status":"ok","timestamp":1719278873030,"user":{"displayName":"Torlakonda Vyshnavi","userId":"08559778629704192597"},"user_tz":-330},"id":"SKkT6q4yP9fu","outputId":"1bd0dd0b-e214-4e7d-ad47-6c29fee2c58b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: pytesseract in /usr/local/lib/python3.10/dist-packages (0.3.10)\n","Requirement already satisfied: transformers==4.28.1 in /usr/local/lib/python3.10/dist-packages (4.28.1)\n","Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.20.0)\n","Requirement already satisfied: evaluate in /usr/local/lib/python3.10/dist-packages (0.4.2)\n","Requirement already satisfied: rouge-score in /usr/local/lib/python3.10/dist-packages (0.1.2)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n","Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (2.15.2)\n","Requirement already satisfied: py7zr in /usr/local/lib/python3.10/dist-packages (0.21.0)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.1) (3.15.3)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.1) (0.23.4)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.1) (1.25.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.1) (24.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.1) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.1) (2024.5.15)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.1) (2.32.3)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.1) (0.13.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.1) (4.66.4)\n","Requirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (9.4.0)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (16.1.0)\n","Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n","Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.0.3)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n","Requirement already satisfied: fsspec[http]<=2024.5.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.5)\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge-score) (1.4.0)\n","Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge-score) (1.16.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n","Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.64.1)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (2.27.0)\n","Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.2.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.6)\n","Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.20.3)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (67.7.2)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.0.3)\n","Requirement already satisfied: texttable in /usr/local/lib/python3.10/dist-packages (from py7zr) (1.7.0)\n","Requirement already satisfied: pycryptodomex>=3.16.0 in /usr/local/lib/python3.10/dist-packages (from py7zr) (3.20.0)\n","Requirement already satisfied: pyzstd>=0.15.9 in /usr/local/lib/python3.10/dist-packages (from py7zr) (0.16.0)\n","Requirement already satisfied: pyppmd<1.2.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from py7zr) (1.1.0)\n","Requirement already satisfied: pybcj<1.1.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from py7zr) (1.0.2)\n","Requirement already satisfied: multivolumefile>=0.2.3 in /usr/local/lib/python3.10/dist-packages (from py7zr) (0.2.3)\n","Requirement already satisfied: inflate64<1.1.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from py7zr) (1.0.0)\n","Requirement already satisfied: brotli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from py7zr) (1.1.0)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from py7zr) (5.9.5)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.2.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.53.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.2)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (5.3.3)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (0.4.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard) (1.3.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers==4.28.1) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.28.1) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.28.1) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.28.1) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.28.1) (2024.6.2)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard) (2.1.5)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n","Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.6.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard) (3.2.2)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n","Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.25.2)\n","Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.4)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n","Looking in indexes: https://download.pytorch.org/whl/cu121\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.0+cu121)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.15.3)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n","Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch) (8.9.2.26)\n","Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.3.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch) (11.0.2.54)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch) (10.3.2.106)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch) (11.4.5.107)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.0.106)\n","Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch) (2.20.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n","Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.0)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.1.105)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n","Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"]}],"source":["## system commands\n","# sudo apt-get install git-lfs\n","\n","!pip install pytesseract transformers==4.28.1 datasets evaluate rouge-score nltk tensorboard py7zr matplotlib\n","!pip install scikit-learn\n","!pip install torch --index-url https://download.pytorch.org/whl/cu121\n"]},{"cell_type":"markdown","metadata":{"id":"YT0Q3pM-P9fx"},"source":["This example will use the [Hugging Face Hub](https://huggingface.co/models) as a remote model versioning service. To be able to push our model to the Hub, you need to register on the [Hugging Face](https://huggingface.co/join).\n","If you already have an account, you can skip this step.\n","After you have an account, we will use the `notebook_login` util from the `huggingface_hub` package to log into our account and store our token (access key) on the disk."]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1210,"status":"ok","timestamp":1719278874236,"user":{"displayName":"Torlakonda Vyshnavi","userId":"08559778629704192597"},"user_tz":-330},"id":"D4OIDtAEP9fy","outputId":"37b685fe-8488-483a-8bc5-f346b66d2957"},"outputs":[{"output_type":"stream","name":"stdout","text":["The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n","Token is valid (permission: write).\n","Your token has been saved to /root/.cache/huggingface/token\n","Login successful\n"]}],"source":["from huggingface_hub import login\n","login(token=\"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\")"]},{"cell_type":"markdown","metadata":{"id":"CEcR1RUTBMr5"},"source":["### Import dependencies"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":1638,"status":"ok","timestamp":1719278875867,"user":{"displayName":"Torlakonda Vyshnavi","userId":"08559778629704192597"},"user_tz":-330},"id":"jPfcxpCc3_Bd"},"outputs":[],"source":["import pandas as pd\n","import matplotlib.pyplot as plt\n","import os\n","import re\n","import glob\n","from datasets import load_dataset\n","import datasets"]},{"cell_type":"markdown","metadata":{"id":"gzO3GxtLP9fz"},"source":["## 2. Load and prepare imdb dataset\n","\n","we will use the [imdb](https://huggingface.co/datasets/imdb) Large Movie Review Dataset. This is a dataset for binary sentiment classification containing substantially more data than previous benchmark datasets. We provide a set of 25,000 highly polar movie reviews for training, and 25,000 for testing. There is additional unlabeled data for use as well.\n"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1719278875868,"user":{"displayName":"Torlakonda Vyshnavi","userId":"08559778629704192597"},"user_tz":-330},"id":"5sA_rRwFP9f0"},"outputs":[],"source":["dataset_id = \"imdb\""]},{"cell_type":"markdown","metadata":{"id":"QWlQtnRnP9f0"},"source":["To load the `imdb` dataset, we use the `load_dataset()` method from the 🤗 Datasets library.\n","\n","<https://huggingface.co/datasets/stanfordnlp/imdb>"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7024,"status":"ok","timestamp":1719278882886,"user":{"displayName":"Torlakonda Vyshnavi","userId":"08559778629704192597"},"user_tz":-330},"id":"JBKcY6IRP9f1","outputId":"4dde3d84-518a-49a8-880c-da0511cd39d4"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Train dataset size: 25000\n","Test dataset size: 25000\n"]}],"source":["from datasets import load_dataset\n","\n","# Load dataset from the hub\n","dataset = load_dataset(dataset_id)\n","\n","print(f\"Train dataset size: {len(dataset['train'])}\")\n","print(f\"Test dataset size: {len(dataset['test'])}\")\n","\n","# Train dataset size: 25000\n","# Test dataset size: 25000"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1719278882886,"user":{"displayName":"Torlakonda Vyshnavi","userId":"08559778629704192597"},"user_tz":-330},"id":"SHEQjZk0Q0mn","outputId":"09ad3db7-3131-4fff-e28b-2372a99834a0"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['text', 'label'],\n","        num_rows: 25000\n","    })\n","    test: Dataset({\n","        features: ['text', 'label'],\n","        num_rows: 25000\n","    })\n","    unsupervised: Dataset({\n","        features: ['text', 'label'],\n","        num_rows: 50000\n","    })\n","})"]},"metadata":{},"execution_count":6}],"source":["dataset"]},{"cell_type":"markdown","metadata":{"id":"ricSiCLrP9f2"},"source":["Lets checkout an example of the dataset."]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1719278882886,"user":{"displayName":"Torlakonda Vyshnavi","userId":"08559778629704192597"},"user_tz":-330},"id":"vgPKUEa1b_50","outputId":"6ca5cfe6-0014-4752-d65a-7f2b99301e95"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'text': '\"I Am Curious: Yellow\" is a risible and pretentious steaming pile. It doesn\\'t matter what one\\'s political views are because this film can hardly be taken seriously on any level. As for the claim that frontal male nudity is an automatic NC-17, that isn\\'t true. I\\'ve seen R-rated films with male nudity. Granted, they only offer some fleeting views, but where are the R-rated films with gaping vulvas and flapping labia? Nowhere, because they don\\'t exist. The same goes for those crappy cable shows: schlongs swinging in the breeze but not a clitoris in sight. And those pretentious indie movies like The Brown Bunny, in which we\\'re treated to the site of Vincent Gallo\\'s throbbing johnson, but not a trace of pink visible on Chloe Sevigny. Before crying (or implying) \"double-standard\" in matters of nudity, the mentally obtuse should take into account one unavoidably obvious anatomical difference between men and women: there are no genitals on display when actresses appears nude, and the same cannot be said for a man. In fact, you generally won\\'t see female genitals in an American film in anything short of porn or explicit erotica. This alleged double-standard is less a double standard than an admittedly depressing ability to come to terms culturally with the insides of women\\'s bodies.',\n"," 'label': 0}"]},"metadata":{},"execution_count":7}],"source":["dataset['train'][1]"]},{"cell_type":"markdown","metadata":{"id":"9NIR6GzgP9f3"},"source":["To train our model we need to convert our inputs (text) to token IDs. This is done by a 🤗 Transformers Tokenizer. If you are not sure what this means check out [chapter 6](https://huggingface.co/course/chapter6/1?fw=tf) of the Hugging Face Course."]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2079,"status":"ok","timestamp":1719278884961,"user":{"displayName":"Torlakonda Vyshnavi","userId":"08559778629704192597"},"user_tz":-330},"id":"qy3D0-vsP9f4","outputId":"6f90a8f6-b929-4730-8603-dc2f08dfa354"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n"]}],"source":["from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n","\n","model_id=\"google/flan-t5-base\"\n","\n","# Load tokenizer of FLAN-t5-base\n","tokenizer = AutoTokenizer.from_pretrained(model_id)"]},{"cell_type":"markdown","metadata":{"id":"ujbT1cMXP9f4"},"source":["before we can start training we need to preprocess our data. Abstractive flan t5 is good for a text2text-generation task. This means our model will take a text as input and generate a text as output. For this we want to understand how long our input and output will be to be able to efficiently batch our data.\n","- as result, we should to convert label from int to string"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":7554,"status":"ok","timestamp":1719278892513,"user":{"displayName":"Torlakonda Vyshnavi","userId":"08559778629704192597"},"user_tz":-330},"id":"R5gXGYlZ0czz"},"outputs":[],"source":["import pandas as pd\n","from datasets import Dataset\n","import random\n","\n","# dataset['train'] = dataset['train'].shuffle(seed=42).select(range(2000))\n","# dataset['test'] = dataset['test'].shuffle(seed=42).select(range(1000))\n","\n","dataset['train'] = dataset['train'].shuffle(seed=42)\n","\n","train_df = pd.DataFrame(dataset['train'])\n","test_df = pd.DataFrame(dataset['test'])\n","dataset.clear()\n","train_df['label'] = train_df['label'].astype(str)\n","test_df['label'] = test_df['label'].astype(str)\n","dataset['train'] = Dataset.from_pandas(train_df)\n","dataset['test'] = Dataset.from_pandas(test_df)"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":40,"status":"ok","timestamp":1719278892515,"user":{"displayName":"Torlakonda Vyshnavi","userId":"08559778629704192597"},"user_tz":-330},"id":"R9LCawlq8twL","outputId":"1beeb636-ac04-4196-a539-8d226e63f39d"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['text', 'label'],\n","        num_rows: 25000\n","    })\n","    test: Dataset({\n","        features: ['text', 'label'],\n","        num_rows: 25000\n","    })\n","})"]},"metadata":{},"execution_count":10}],"source":["dataset"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":117,"referenced_widgets":["49488e185cd34ea2888082d24b59cb8b","5aa2502de89642c5a3189771f799e854","1f42b9c6087c43909c97f6c989cefded","9b1e3f8dff4047b0a65d0a609caa8cbf","eb092cfbada5492aac077a7c24c1d733","f2666c73af6849eb8cbae3e56c01a19e","c2cbca1386ee4182851e893035613645","e307f742ce16464c8e93441f7aae3ecc","4dd9a86670864aba8806d9ad12c77c68","215443229f0b4787ae3bfbf908c5135d","badea53cec3d4a59b1991c35da68abec","a24aa00b169746c68bd529cd375c173a","ca64bf03f338420cbafad000fc0d30ea","ca85438a4a1843b38ff8ef3687d90d6d","6fda2419f826411da2ddf3916d6acbb8","d3b7f4e81b794da384b8e7844673994c","a7a15c3efcee46a1b54d158d6cec4642","70d3033a90334c08a3fcc5ed247e604e","dfca0756ffe94027be51a0a9d164a45d","8008932398ef4c428ea4184a157a9cd4","ef58a45a817a46c2a54aa71c2bc3834c","6e25ad1723324aa09c6e23f84ebdc4e8"]},"executionInfo":{"elapsed":98169,"status":"ok","timestamp":1719278990647,"user":{"displayName":"Torlakonda Vyshnavi","userId":"08559778629704192597"},"user_tz":-330},"id":"exxzuraIc_Zb","outputId":"e7199c5d-1bed-4f8c-99ea-576aaeb0e03b"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/50000 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"49488e185cd34ea2888082d24b59cb8b"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Max source length: 512\n"]},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/50000 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a24aa00b169746c68bd529cd375c173a"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Max target length: 3\n"]}],"source":["from datasets import concatenate_datasets\n","\n","# The maximum total input sequence length after tokenization.\n","# Sequences longer than this will be truncated, sequences shorter will be padded.\n","tokenized_inputs = concatenate_datasets([dataset[\"train\"], dataset[\"test\"]]).map(lambda x: tokenizer(x[\"text\"], truncation=True), batched=True, remove_columns=['text', 'label'])\n","max_source_length = max([len(x) for x in tokenized_inputs[\"input_ids\"]])\n","print(f\"Max source length: {max_source_length}\")\n","\n","# The maximum total sequence length for target text after tokenization.\n","# Sequences longer than this will be truncated, sequences shorter will be padded.\"\n","tokenized_targets = concatenate_datasets([dataset[\"train\"], dataset[\"test\"]]).map(lambda x: tokenizer(x[\"label\"], truncation=True), batched=True, remove_columns=['text', 'label'])\n","max_target_length = max([len(x) for x in tokenized_targets[\"input_ids\"]])\n","print(f\"Max target length: {max_target_length}\")"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":99,"referenced_widgets":["eb5adbdf125440c68f9798ed4a313467","cbd3560f82414d93b191cd04ae7e2fe2","38530684ecc8475ca6d0f6cb27da83a1","545048a34a0e4349bc9d7c9e15554082","149aa5c91927437aae908e58149256e5","4521844e16684ccea5ba605ab43b281e","43a7e75547ae4b0b9680a70ba3639750","61d321fb043b423b88c8eea785e76dc3","d53c79d038544a6ab6de813777e19dd6","3f2b66e493fc46488994f7b8723e2580","6daf4ac8e7204bf5af2fac7c97ded78c","29730d54c06e441c8d92c5d452201180","c3505e25737e4e88a6473cdd08917873","902fd06c95f1468fa2b4d5099908e4e5","8372739be78c4929872ccfe1d0afb908","8a70c4bd259d41aabcfb9bbc1a2104b2","3672454f658347728f7dea4fb53f72e5","7b74927c17a94cd98c8b8929d3d552d1","708b3268fd3048c09aaf720045fc5849","f73594fc643c4f18a49bf62feb2bf8f8","4fabf9e592a3433e8eef1c82bf7570bd","fc0fe613d7f943168ebfcf4f585edf98"]},"executionInfo":{"elapsed":71272,"status":"ok","timestamp":1719279061910,"user":{"displayName":"Torlakonda Vyshnavi","userId":"08559778629704192597"},"user_tz":-330},"id":"sKKGwPR9P9f5","outputId":"7ce9441f-e545-493c-8460-fd837b86f3c3"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/25000 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eb5adbdf125440c68f9798ed4a313467"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/25000 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"29730d54c06e441c8d92c5d452201180"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Keys of tokenized dataset: ['input_ids', 'attention_mask', 'labels']\n"]}],"source":["def preprocess_function(sample, padding=\"max_length\"):\n","    # add prefix to the input for t5\n","    inputs = [item for item in sample[\"text\"]]\n","\n","    # tokenize inputs\n","    model_inputs = tokenizer(inputs, max_length=max_source_length, padding=padding, truncation=True)\n","\n","    # Tokenize targets with the `text_target` keyword argument\n","    labels = tokenizer(text_target=sample[\"label\"], max_length=max_target_length, padding=padding, truncation=True)\n","\n","    # If we are padding here, replace all tokenizer.pad_token_id in the labels by -100 when we want to ignore\n","    # padding in the loss.\n","    if padding == \"max_length\":\n","        labels[\"input_ids\"] = [\n","            [(l if l != tokenizer.pad_token_id else -100) for l in label] for label in labels[\"input_ids\"]\n","        ]\n","\n","    model_inputs[\"labels\"] = labels[\"input_ids\"]\n","    return model_inputs\n","\n","tokenized_dataset = dataset.map(preprocess_function, batched=True, remove_columns=['text', 'label'])\n","print(f\"Keys of tokenized dataset: {list(tokenized_dataset['train'].features)}\")"]},{"cell_type":"markdown","metadata":{"id":"zEbhOAeCP9f6"},"source":["## 3. Fine-tune and evaluate FLAN-T5\n","\n","After we have processed our dataset, we can start training our model. Therefore we first need to load our [FLAN-T5](https://huggingface.co/models?search=flan-t5) from the Hugging Face Hub. In the example we are using a instance with a NVIDIA V100 meaning that we will fine-tune the `base` version of the model.\n","_I plan to do a follow-up post on how to fine-tune the `xxl` version of the model using Deepspeed._\n"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12859,"status":"ok","timestamp":1719279074766,"user":{"displayName":"Torlakonda Vyshnavi","userId":"08559778629704192597"},"user_tz":-330},"id":"swteeCAoP9f6","outputId":"9628f6fa-f1c8-4230-e4a4-ea03f523710c"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n"]}],"source":["from transformers import AutoModelForSeq2SeqLM\n","\n","# huggingface hub model id\n","model_id=\"google/flan-t5-base\"\n","\n","# load model from the hub\n","model = AutoModelForSeq2SeqLM.from_pretrained(model_id)"]},{"cell_type":"markdown","metadata":{"id":"0Dp2ZaLjP9f6"},"source":["We want to evaluate our model during training. The `Trainer` supports evaluation during training by providing a `compute_metrics`.  \n","The most commonly used metrics to evaluate summarization task is [rogue_score](https://en.wikipedia.org/wiki/ROUGE_(metric)) short for Recall-Oriented Understudy for Gisting Evaluation). This metric does not behave like the standard accuracy: it will compare a generated summary against a set of reference summaries\n","\n","We are going to use `evaluate` library to evaluate the `rogue` score."]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6782,"status":"ok","timestamp":1719279081536,"user":{"displayName":"Torlakonda Vyshnavi","userId":"08559778629704192597"},"user_tz":-330},"id":"osGhQTz4P9f7","outputId":"f3fd81d0-e642-4bdb-969b-75f461a86745"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"]}],"source":["import evaluate\n","import nltk\n","import numpy as np\n","from nltk.tokenize import sent_tokenize\n","nltk.download(\"punkt\")\n","\n","# Metric\n","metric = evaluate.load(\"f1\")\n","\n","# helper function to postprocess text\n","def postprocess_text(preds, labels):\n","    preds = [pred.strip() for pred in preds]\n","    labels = [label.strip() for label in labels]\n","\n","    # rougeLSum expects newline after each sentence\n","    preds = [\"\\n\".join(sent_tokenize(pred)) for pred in preds]\n","    labels = [\"\\n\".join(sent_tokenize(label)) for label in labels]\n","\n","    return preds, labels\n","\n","def compute_metrics(eval_preds):\n","    preds, labels = eval_preds\n","    if isinstance(preds, tuple):\n","        preds = preds[0]\n","    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n","    # Replace -100 in the labels as we can't decode them.\n","    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n","    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n","\n","    # Some simple post-processing\n","    decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n","\n","    result = metric.compute(predictions=decoded_preds, references=decoded_labels, average='macro')\n","    result = {k: round(v * 100, 4) for k, v in result.items()}\n","    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds]\n","    result[\"gen_len\"] = np.mean(prediction_lens)\n","    return result"]},{"cell_type":"markdown","metadata":{"id":"9X0ZrYzTP9f8"},"source":["Before we can start training is to create a `DataCollator` that will take care of padding our inputs and labels. We will use the `DataCollatorForSeq2Seq` from the 🤗 Transformers library."]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":20,"status":"ok","timestamp":1719279081537,"user":{"displayName":"Torlakonda Vyshnavi","userId":"08559778629704192597"},"user_tz":-330},"id":"hXJvOMTnP9f8"},"outputs":[],"source":["from transformers import DataCollatorForSeq2Seq\n","\n","# we want to ignore tokenizer pad token in the loss\n","label_pad_token_id = -100\n","# Data collator\n","data_collator = DataCollatorForSeq2Seq(\n","    tokenizer,\n","    model=model,\n","    label_pad_token_id=label_pad_token_id,\n","    pad_to_multiple_of=8\n",")"]},{"cell_type":"markdown","metadata":{"id":"oE_7wq32P9f8"},"source":["The last step is to define the hyperparameters (`TrainingArguments`) we want to use for our training. We are leveraging the [Hugging Face Hub](https://huggingface.co/models) integration of the `Trainer` to automatically push our checkpoints, logs and metrics during training into a repository."]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2860,"status":"ok","timestamp":1719279084378,"user":{"displayName":"Torlakonda Vyshnavi","userId":"08559778629704192597"},"user_tz":-330},"id":"6ZxlsgznP9f9","outputId":"34df2e9f-d871-4cfd-e8c6-8f051d08cd9f"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'Repository' (from 'huggingface_hub.repository') is deprecated and will be removed from version '1.0'. Please prefer the http-based alternatives instead. Given its large adoption in legacy code, the complete removal is only planned on next major release.\n","For more details, please read https://huggingface.co/docs/huggingface_hub/concepts/git_vs_http.\n","  warnings.warn(warning_message, FutureWarning)\n","/content/flan-t5-base-imdb-text-classification is already a clone of https://huggingface.co/Vyshu2103/flan-t5-base-imdb-text-classification. Make sure you pull the latest changes with `repo.git_pull()`.\n","WARNING:huggingface_hub.repository:/content/flan-t5-base-imdb-text-classification is already a clone of https://huggingface.co/Vyshu2103/flan-t5-base-imdb-text-classification. Make sure you pull the latest changes with `repo.git_pull()`.\n"]}],"source":["from huggingface_hub import HfFolder\n","from transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments\n","\n","# Hugging Face repository id\n","repository_id = f\"{model_id.split('/')[1]}-imdb-text-classification\"\n","\n","# Define training args\n","training_args = Seq2SeqTrainingArguments(\n","    output_dir=repository_id,\n","    per_device_train_batch_size=8,\n","    per_device_eval_batch_size=8,\n","    predict_with_generate=True,\n","    fp16=False, # Overflows with fp16\n","    learning_rate=3e-4,\n","\n","    num_train_epochs=2,\n","    # logging & evaluation strategies\n","    logging_dir=f\"{repository_id}/logs\",\n","    logging_strategy=\"epoch\",\n","    # logging_steps=1000,\n","    evaluation_strategy=\"no\",\n","    save_strategy=\"epoch\",\n","    save_total_limit=2,\n","    load_best_model_at_end=False,\n","    # metric_for_best_model=\"overall_f1\",\n","    # push to hub parameters\n","    report_to=\"tensorboard\",\n","    push_to_hub=True,\n","    hub_strategy=\"every_save\",\n","    hub_model_id=repository_id,\n","    hub_token=HfFolder.get_token(),\n",")\n","\n","# Create Trainer instance\n","trainer = Seq2SeqTrainer(\n","    model=model,\n","    args=training_args,\n","    data_collator=data_collator,\n","    train_dataset=tokenized_dataset[\"train\"],\n","    eval_dataset=tokenized_dataset[\"test\"],\n","    compute_metrics=compute_metrics,\n",")"]},{"cell_type":"markdown","metadata":{"id":"gTfdbwXfP9f9"},"source":["We can start our training by using the `train` method of the `Trainer`."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f8KanGHpP9f-","outputId":"997ee8ca-90c6-4e39-d215-ae5812021b63"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"]}],"source":["# Start training\n","trainer.train()"]},{"cell_type":"markdown","metadata":{"id":"rdi_pJLBP9f-"},"source":["Nice, we have trained our model. 🎉 Lets run evaluate the best model again on the test set.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"x_RRbvvoP9f-"},"outputs":[],"source":["trainer.evaluate()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EgKyYOXWP9gA"},"outputs":[],"source":["# Save our tokenizer and create model card\n","tokenizer.save_pretrained(repository_id)\n","trainer.create_model_card()\n","# Push the results to the hub\n","trainer.push_to_hub()"]},{"cell_type":"markdown","metadata":{"id":"sRCjQfZ8B1p8"},"source":["## 4. Run Inference and Classification Report"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2aP6bVVfmOhf"},"outputs":[],"source":["from tqdm.auto import tqdm\n","\n","samples_number = len(dataset['test'])\n","progress_bar = tqdm(range(samples_number))\n","predictions_list = []\n","labels_list = []\n","for i in range(samples_number):\n","  text = dataset['test']['text'][i]\n","  inputs = tokenizer.encode_plus(text, padding='max_length', max_length=512, return_tensors='pt').to('cuda')\n","  outputs = model.generate(inputs['input_ids'], attention_mask=inputs['attention_mask'], max_length=150, num_beams=4, early_stopping=True)\n","  prediction = tokenizer.decode(outputs[0], skip_special_tokens=True)\n","  predictions_list.append(prediction)\n","  labels_list.append(dataset['test']['label'][i])\n","\n","  progress_bar.update(1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XCU7WxZWkjU1"},"outputs":[],"source":["str_labels_list = []\n","for i in range(len(labels_list)):\n","    str_labels_list.append(str(labels_list[i]))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"X3iqrE4CmOhl"},"outputs":[],"source":["from sklearn.metrics import classification_report\n","\n","report = classification_report(str_labels_list, predictions_list, zero_division=0)\n","print(report)"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"pytorch","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"},"vscode":{"interpreter":{"hash":"2d58e898dde0263bc564c6968b04150abacfd33eed9b19aaa8e45c040360e146"}},"widgets":{"application/vnd.jupyter.widget-state+json":{"49488e185cd34ea2888082d24b59cb8b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5aa2502de89642c5a3189771f799e854","IPY_MODEL_1f42b9c6087c43909c97f6c989cefded","IPY_MODEL_9b1e3f8dff4047b0a65d0a609caa8cbf"],"layout":"IPY_MODEL_eb092cfbada5492aac077a7c24c1d733"}},"5aa2502de89642c5a3189771f799e854":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f2666c73af6849eb8cbae3e56c01a19e","placeholder":"​","style":"IPY_MODEL_c2cbca1386ee4182851e893035613645","value":"Map: 100%"}},"1f42b9c6087c43909c97f6c989cefded":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e307f742ce16464c8e93441f7aae3ecc","max":50000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4dd9a86670864aba8806d9ad12c77c68","value":50000}},"9b1e3f8dff4047b0a65d0a609caa8cbf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_215443229f0b4787ae3bfbf908c5135d","placeholder":"​","style":"IPY_MODEL_badea53cec3d4a59b1991c35da68abec","value":" 50000/50000 [01:26&lt;00:00, 878.58 examples/s]"}},"eb092cfbada5492aac077a7c24c1d733":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f2666c73af6849eb8cbae3e56c01a19e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c2cbca1386ee4182851e893035613645":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e307f742ce16464c8e93441f7aae3ecc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4dd9a86670864aba8806d9ad12c77c68":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"215443229f0b4787ae3bfbf908c5135d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"badea53cec3d4a59b1991c35da68abec":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a24aa00b169746c68bd529cd375c173a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ca64bf03f338420cbafad000fc0d30ea","IPY_MODEL_ca85438a4a1843b38ff8ef3687d90d6d","IPY_MODEL_6fda2419f826411da2ddf3916d6acbb8"],"layout":"IPY_MODEL_d3b7f4e81b794da384b8e7844673994c"}},"ca64bf03f338420cbafad000fc0d30ea":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a7a15c3efcee46a1b54d158d6cec4642","placeholder":"​","style":"IPY_MODEL_70d3033a90334c08a3fcc5ed247e604e","value":"Map: 100%"}},"ca85438a4a1843b38ff8ef3687d90d6d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_dfca0756ffe94027be51a0a9d164a45d","max":50000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8008932398ef4c428ea4184a157a9cd4","value":50000}},"6fda2419f826411da2ddf3916d6acbb8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ef58a45a817a46c2a54aa71c2bc3834c","placeholder":"​","style":"IPY_MODEL_6e25ad1723324aa09c6e23f84ebdc4e8","value":" 50000/50000 [00:01&lt;00:00, 35574.02 examples/s]"}},"d3b7f4e81b794da384b8e7844673994c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a7a15c3efcee46a1b54d158d6cec4642":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"70d3033a90334c08a3fcc5ed247e604e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"dfca0756ffe94027be51a0a9d164a45d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8008932398ef4c428ea4184a157a9cd4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ef58a45a817a46c2a54aa71c2bc3834c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6e25ad1723324aa09c6e23f84ebdc4e8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"eb5adbdf125440c68f9798ed4a313467":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_cbd3560f82414d93b191cd04ae7e2fe2","IPY_MODEL_38530684ecc8475ca6d0f6cb27da83a1","IPY_MODEL_545048a34a0e4349bc9d7c9e15554082"],"layout":"IPY_MODEL_149aa5c91927437aae908e58149256e5"}},"cbd3560f82414d93b191cd04ae7e2fe2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4521844e16684ccea5ba605ab43b281e","placeholder":"​","style":"IPY_MODEL_43a7e75547ae4b0b9680a70ba3639750","value":"Map: 100%"}},"38530684ecc8475ca6d0f6cb27da83a1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_61d321fb043b423b88c8eea785e76dc3","max":25000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d53c79d038544a6ab6de813777e19dd6","value":25000}},"545048a34a0e4349bc9d7c9e15554082":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3f2b66e493fc46488994f7b8723e2580","placeholder":"​","style":"IPY_MODEL_6daf4ac8e7204bf5af2fac7c97ded78c","value":" 25000/25000 [00:37&lt;00:00, 674.16 examples/s]"}},"149aa5c91927437aae908e58149256e5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4521844e16684ccea5ba605ab43b281e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"43a7e75547ae4b0b9680a70ba3639750":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"61d321fb043b423b88c8eea785e76dc3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d53c79d038544a6ab6de813777e19dd6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3f2b66e493fc46488994f7b8723e2580":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6daf4ac8e7204bf5af2fac7c97ded78c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"29730d54c06e441c8d92c5d452201180":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c3505e25737e4e88a6473cdd08917873","IPY_MODEL_902fd06c95f1468fa2b4d5099908e4e5","IPY_MODEL_8372739be78c4929872ccfe1d0afb908"],"layout":"IPY_MODEL_8a70c4bd259d41aabcfb9bbc1a2104b2"}},"c3505e25737e4e88a6473cdd08917873":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3672454f658347728f7dea4fb53f72e5","placeholder":"​","style":"IPY_MODEL_7b74927c17a94cd98c8b8929d3d552d1","value":"Map: 100%"}},"902fd06c95f1468fa2b4d5099908e4e5":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_708b3268fd3048c09aaf720045fc5849","max":25000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f73594fc643c4f18a49bf62feb2bf8f8","value":25000}},"8372739be78c4929872ccfe1d0afb908":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4fabf9e592a3433e8eef1c82bf7570bd","placeholder":"​","style":"IPY_MODEL_fc0fe613d7f943168ebfcf4f585edf98","value":" 25000/25000 [00:33&lt;00:00, 785.89 examples/s]"}},"8a70c4bd259d41aabcfb9bbc1a2104b2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3672454f658347728f7dea4fb53f72e5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7b74927c17a94cd98c8b8929d3d552d1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"708b3268fd3048c09aaf720045fc5849":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f73594fc643c4f18a49bf62feb2bf8f8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4fabf9e592a3433e8eef1c82bf7570bd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fc0fe613d7f943168ebfcf4f585edf98":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}